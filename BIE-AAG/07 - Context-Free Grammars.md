# Context-Free Grammars

Context-free grammars are used to describe most of the syntactic structures of programming languages.

We say that a context-free grammar $G = (N,\Sigma,P,S)$ is **ambiguous** if there exists a sentence $w \in L(G)$ that is the result of two or more different parse trees. Otherwise we say that the grammar is **unambiguous**. If a language can only be generated by an ambiguous grammar, then it is an **ambiguous language**.

In many cases it is possible to remove the ambiguousness from the grammar, but if it is impossible, we call them **inherently ambiguous languages**. It is impossible to create a algorithm to decide whether a given GFG is ambiguous.

A context-free grammar $G = (N,\Sigma,P,S)$ is **cycle-free** if not derivation of the following type is possible:
$$
A \Rarr^*A
$$
A context-free grammar $G = (N,\Sigma,P,S)$ is **proper** is it is cycle-free, $\epsilon$-rule free and it contains no redundant symbols.

There are also a few important theorems:

- **Rule Exclusion Theorem**:

  Let context-free grammar $G = (N,\Sigma,P,S)$  and $(A\rarr \alpha B \beta) \in P$ with $\beta,\alpha \in (N\cup\Sigma)^*, B \in N, A \neq B$ .

  Let $B\rarr \gamma_1 | \dots|\gamma_k$ be all the rules in $P$ with the symbol $B$ on the left-hand side. Let $G'=(N,\Sigma,P',S)$ where:
  $$
  P'=P \cup\{A \rarr \alpha \gamma_1\beta|\dots|\alpha\gamma_k\beta\} \setminus \{A \rarr \alpha B \beta\}
  $$
  Then:
  $$
  L(G) = L(G')
  $$

- If a context-free grammar $G = (N,\Sigma,P,S)$  has not $\epsilon$-rules and simple rules, the it is cycle-free.

- If $L$ is a context-free language, then it can be generated by some proper grammar $G$.

## Transformations of CFG

### Decide whether the language is empty

<img src="Resources/07 - Context-Free Grammars/image-20201227192306407.png" alt="image-20201227192306407" style="zoom:67%;" />

### Removal of unreachable symbols

We say that a symbol $X \in N \cup \Sigma$ is **unreachable** in a context-free grammar $G = (N,\Sigma,P,S)$ if $X$ does not appear in any sentential form, meaning that there are no derivations that of the form:
$$
S \implies\alpha X\beta,~~~~ \alpha,\beta \in (N\cup \Sigma)^*
$$
We can remove these symbols with the following algorithm:

1. Create a set with only the starting symbol $S$:
   $$
   V^0 = \{S\}
   $$

2. Add to the set $V^{i+1}$ all the terminal and non-terminal symbols that are reachable from the symbols in the set $V^i$.

3. If $V^i = V^{i+1}$ continue to the next step, else repeat step $2.$

4. Remove all symbols that are not in the set $V^i$

A more formal representation of this algorithm can be found here:

<img src="Resources/07 - Context-Free Grammars/image-20201227192637471.png" alt="image-20201227192637471" style="zoom:67%;" />

### Exclusion of redundant symbols

A symbol $X\in N\cup \Sigma$ is **redundant** in $G = (N,\Sigma,P,S)$if there does not exists:
$$
S \Rightarrow^* wXi \Rightarrow^*wxy,~~~~ w,x,y \in \Sigma^* 
$$
Also, if a context-free grammar is **reduced** if it does not contain any redundant symbol. We can remove all redundant symbols with the following algorithm:

1. Create an empty set:
   $$
   N_t^0 =\{\}
   $$

2. We add all the non-terminal symbols that have at least one production rule with either an $\epsilon$ or a sequence of only terminal symbols in the right-hand side.:
   $$
   \array{A \rarr \epsilon &
   A \rarr a}\\
   A\in N, a\ \in T^*
   $$

3. We add to the set $N_t^{i+1}$ all the non-terminal symbols that have at least one production with either an $\epsilon$, or a sequence of terminal symbols or non-terminal symbols that are in the set $N_t^i$ in the right-hand side:
   $$
   \array{A \rarr \epsilon & A \rarr a}\\
   A \in N, a \in (T \cup N_t^i)^*
   $$

4. If $N_t^i = N_t^{i+1}$, then we continue to the next step, else we must repeat step $4.$

5. We perform the algorithm *removal of unreachable states*.

### Exclusion of $\epsilon$-rules

A context-free grammar $G = (N,\Sigma,P,S)$ is **$\epsilon$-rule free** if:

- $P$ contains no $\epsilon$-rule

- $P$ contains only one $\epsilon$-rule of the form:
  $$
  S \Rarr\epsilon
  $$
  And $S$ does not appear on the right side of any rule in $P$.

We can remove all $\epsilon$-rules with the following algorithm:

1. Create an empty set:
   $$
   N_\epsilon^0=\{\}
   $$

2. Add all non-terminal symbols have an $\epsilon$-rule.

3. Add to the set $N_\epsilon^{i+1}$ all non-terminal symbols that can lead to an $\epsilon$-rule from a transition from one of the states within the set $N_\epsilon^i$.

4. If $N_\epsilon^{i-1} = N_\epsilon^i$, continue to the next step, else repeat step $3.$

5. Remove all $\epsilon$-rules from the grammar

6. Precompute the new rules taking into consideration the elements in the set.

Additionally, if the grammar can generate an empty string then we have 2 options:

- If the starting symbol $S$ is also in the right-hand side of a production rule, then we replace $S$ with $S'$ as starting symbol and add one more rule:
  $$
  S'\rarr S| \epsilon 
  $$

- If the starting symbol $S$ is not in the right-hand side of a production rule, we add the following rule to the grammar:
  $$
  S\rarr \epsilon
  $$

A more formal version of this algorithm can be found here:

<img src="Resources/07 - Context-Free Grammars/image-20201227194730374.png" alt="image-20201227194730374" style="zoom:67%;" />

### Exclusion of simple rules

In order to remove all simple rules from a grammar we must follow this states:

1. We have to create an empty set for each non-terminal symbol:
   $$
   \array{N_A^0=\{A\} &\forall A\in N}
   $$

2. For each set $N_A$ we have to apply the following rules:

   1. Add all non-terminal symbols that are reachable from the symbols in the set $N^i_A$ with a simple rule.
   2.  If $N_A^i = N^{i-1}_A$, then I will continue to the next step, else repeat step $1.$

3. Remove all simple rules

4. Go through all sets and modify the current rules to generate the same grammar as before without the simple rules. The relations from one symbol to another should be clear from the sets.

A more formal version of the algorithm can be found here:

<img src="Resources/07 - Context-Free Grammars/image-20201227194753003.png" alt="image-20201227194753003" style="zoom:67%;" />

## Chomsky Normal Form

A context-free grammar $G = (N,\Sigma,P,S)$  is in **Chomsky Normal Form** if every rule in $P$ is in one of the following forms:

- $A\rarr BC$
- $A\rarr a$
- $S \rarr \epsilon$ if $\epsilon \in L(G)$ and $S$ does not appear in the right-hand side of any rule. 

$A,S,B,C \in N, a \in \Sigma$.

> Let $L$ be a context-free language, $L$ is a language generated by a grammar in Chomsky Normal Form.

Because of this theorem, we can convert all grammars into Chomsky Normal Form with the following algorithm:

<img src="Resources/07 - Context-Free Grammars/image-20201227202758071.png" alt="image-20201227202758071" style="zoom:67%;" />

We can write this algorithm in a simpler way. To apply it we only need to follow this steps:

1. Remove all $\epsilon$-Closures

2. Remove all simple production rules. This are the rules with the following form:
   $$
   \array{A \rarr B & A,B \in N}
   $$

3. Remove all unnecessary or redundant states.

4. If we have a rule that mixes a terminal and a non-terminal symbol, we have to replace the terminal symbol for a new, non-terminal one. For example:
$$
\array{A\rarr bC & \Rarr & A \rarr b'C, b' \rarr b}
   \\ A,b',C \in N, b \in T
$$

5. All rules composed only by non-terminal symbols must have only 2 symbols on their right-hand side. For example:
$$
   \array{ A\rarr BCD& \Rarr& A\rarr B<\!CD\!>, <\!CD\!> \rarr CD }
$$
### Cocke-Younger-Kasami Algorithm

For each context-free grammar $G = (N,\Sigma,P,S)$ in Chomsky Normal Form there exist an algorithm that can decide if a given string is part of the language the grammar generates. 

This algorithm has complexity of $O(n^3)$ and we can find it here:

1. Convert the grammar to Chomsky Normal Form.

2. Create a table with $|w|$ rows and columns, being $w$ the word we want to verify. We are not going to use the cells that if you sum their column and row, its larger than $|w|$.

   |      |          |  1   |  2   | $\dots$ |  3   |
   | :--: | :------: | :--: | :--: | :-----: | :--: |
   |  w   |    1     |      |      |         |      |
   |  o   |    2     |      |      |         |  -   |
   |  r   | $\vdots$ |      |      |    -    |  -   |
   |  d   |    4     |      |  -   |    -    |  -   |

3. We will start form the first column labeled $1$. We will go though all the rows of the column, according to the index of the row, we are going to find all non-terminal symbols that can directly generate that terminal symbol and add them to that cell.

4. For the second row, we are going to see which non-terminals generate 2 of those symbols. For this we need to get pairs of cells from the the first column and do the cartesian product of both sets. For example if we want to calculate the cell $(1,2)$ we need to do calculate $(1,1) \times (2,1)$ and get all possible combinations of symbols.

   The same process is repeated for all elements of columns 2, and its calculated always in the same way:
$$
   (i,2) = (i,1) \times (i+1,1)
$$
   Now that we have the sets we need to store only the non-terminal symbols that have at least one production rule to generate any of those combinations.

5. Moving to the next column, we need to do the same procedure but this time we need to generate 3 terminal symbols, so we are mixing different cartesian products:
$$
   (i,3) = (i,1) \times (i+1,2) \cup (i,2)\times (i+2,1)
$$
6. From now on we have to continue this procedure for all columns and just modifying how we calculate the set of cartesian products.  The idea is to split the string of length $|w|$ into $|w|-1$ sets that we are joining. These  sets will split the strings into:
$$
   [|w|-1,1], [|w|-2,2], \dots,[|w|-i,i], \dots ,[1,|w|-1]
$$
A more formal version of the algorithm can be found here:

<img src="Resources/07 - Context-Free Grammars/image-20201227203126212.png" alt="image-20201227203126212" style="zoom:67%;" />

## Recursive Context-Free Grammar

A non terminal symbol $A$ in a context-free grammar $G = (N,\Sigma,P,S)$ is called **recursive** if there exists a derivation:
$$
A \Rarr^*\alpha A \beta
$$
For some $\alpha,\beta \in (N\cup\Sigma)^*$. If $\alpha = \epsilon$, then we call $A$ a **left-recursive symbol**, in the same way we call $A$ a **right-recursive symbol** if $\beta = \epsilon$.

If a grammar has at least one non-terminal recursive symbol, we call it a **recursive grammar**. 

To remove left-recursion from a grammar we have two methods:

- **Direct Left-Recursion Removal**: For all production rules have the following shape:
$$
  A \rarr A\alpha|B
$$
  We must convert them to:
$$
  \array{A \rarr \beta A' & A'\rarr\alpha|\alpha A'}
  \\ \alpha,\beta \in (T \cup N)^*, A,A' \in N
$$

- **Indirect Left-Recursion Removal**: This is a more complex procedure and we can do it in the following way:

  1. Convert our grammar into a proper grammar, without $\epsilon$-transitions, simple rules or unnecessary states.
  2. Order the non-terminal states and enumerate them. For each state we are going to analyze all rules. If the rule starts with a state that we have already visited, then we remove the rule and precompute all new rules.
  3. Apply the direct Left-Recursion Removal algorithm



  