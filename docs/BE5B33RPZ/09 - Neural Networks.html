<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>09 - Neural Networks.md</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <style>
        html {
    overflow-x: initial !important;
}

:root {
    --bg-color: #ffffff;
    --text-color: #333333;
    --select-text-bg-color: #B5D6FC;
    --select-text-font-color: auto;
    --monospace: "Lucida Console", Consolas, "Courier", monospace;
}

html {
    font-size: 14px;
    background-color: var(--bg-color);
    color: var(--text-color);
    font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    -webkit-font-smoothing: antialiased;
}

body {
    margin: 5%;
    padding: 0px;
    height: auto;
    bottom: 0px;
    top: 0px;
    left: 0px;
    right: 0px;
    font-size: 1rem;
    line-height: 1.42857;
    overflow-x: hidden;
    background: inherit;
    tab-size: 4;
    max-width: 100%;
}

iframe {
    margin: auto;
}

a.url {
    word-break: break-all;
}

a:active, a:hover {
    outline: 0px;
}

.in-text-selection, ::selection {
    text-shadow: none;
    background: var(--select-text-bg-color);
    color: var(--select-text-font-color);
}

#write {
    margin: 0px auto;
    height: auto;
    width: inherit;
    word-break: normal;
    overflow-wrap: break-word;
    position: relative;
    white-space: normal;
    overflow-x: visible;
    padding-top: 40px;
}

#write.first-line-indent p {
    text-indent: 2em;
}

#write.first-line-indent li p, #write.first-line-indent p * {
    text-indent: 0px;
}

#write.first-line-indent li {
    margin-left: 2em;
}

.for-image #write {
    padding-left: 8px;
    padding-right: 8px;
}

body.typora-export {
    padding-left: 30px;
    padding-right: 30px;
}

.typora-export .footnote-line, .typora-export li, .typora-export p {
    white-space: pre-wrap;
}

@media screen and (max-width: 500px) {
    body.typora-export {
        padding-left: 0px;
        padding-right: 0px;
    }

    #write {
        padding-left: 20px;
        padding-right: 20px;
    }

    .CodeMirror-sizer {
        margin-left: 0px !important;
    }

    .CodeMirror-gutters {
        display: none !important;
    }
}

#write li > figure:last-child {
    margin-bottom: 0.5rem;
}

#write ol, #write ul {
    position: relative;
}

img {
    max-width: 100%;
    vertical-align: middle;
}

button, input, select, textarea {
    color: inherit;
    font: inherit;
}

input[type="checkbox"], input[type="radio"] {
    line-height: normal;
    padding: 0px;
}

*, ::after, ::before {
    box-sizing: border-box;
}

#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre {
    width: inherit;
}

#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p {
    position: relative;
}

p {
    line-height: inherit;
}

h1, h2, h3, h4, h5, h6 {
    break-after: avoid-page;
    break-inside: avoid;
    orphans: 2;
}

p {
    orphans: 4;
}

h1 {
    font-size: 2rem;
    text-align: center
}

h2 {
    font-size: 1.8rem;
}

h3 {
    font-size: 1.6rem;
}

h4 {
    font-size: 1.4rem;
}

h5 {
    font-size: 1.2rem;
}

h6 {
    font-size: 1rem;
}

.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p {
    margin-top: 1rem;
    margin-bottom: 1rem;
}

.hidden {
    display: none;
}

.md-blockmeta {
    color: rgb(204, 204, 204);
    font-weight: 700;
    font-style: italic;
}

a {
    cursor: pointer;
}

sup.md-footnote {
    padding: 2px 4px;
    background-color: rgba(238, 238, 238, 0.7);
    color: rgb(85, 85, 85);
    border-radius: 4px;
    cursor: pointer;
}

sup.md-footnote a, sup.md-footnote a:hover {
    color: inherit;
    text-transform: inherit;
    text-decoration: inherit;
}

#write input[type="checkbox"] {
    cursor: pointer;
    width: inherit;
    height: inherit;
}

figure {
    overflow-x: auto;
    margin: 1.2em 0px;
    max-width: calc(100% + 16px);
    padding: 0px;
}

figure > table {
    margin: 0px !important;
}

tr {
    break-inside: avoid;
    break-after: auto;
}

thead {
    display: table-header-group;
}

table {
    border-collapse: collapse;
    border-spacing: 0px;
    width: 100%;
    overflow: auto;
    break-inside: auto;
    text-align: left;
}

table.md-table td {
    min-width: 32px;
}

.CodeMirror-gutters {
    border-right: 0px;
    background-color: inherit;
}

.CodeMirror-linenumber {
    user-select: none;
}

.CodeMirror {
    text-align: left;
}

.CodeMirror-placeholder {
    opacity: 0.3;
}

.CodeMirror pre {
    padding: 0px 4px;
}

.CodeMirror-lines {
    padding: 0px;
}

div.hr:focus {
    cursor: none;
}

#write pre {
    white-space: pre-wrap;
}

#write.fences-no-line-wrapping pre {
    white-space: pre;
}

#write pre.ty-contain-cm {
    white-space: normal;
}

.CodeMirror-gutters {
    margin-right: 4px;
}

.md-fences {
    font-size: 0.9rem;
    display: block;
    break-inside: avoid;
    text-align: left;
    overflow: visible;
    white-space: pre;
    background: inherit;
    position: relative !important;
}

.md-diagram-panel {
    width: 100%;
    margin-top: 10px;
    text-align: center;
    padding-top: 0px;
    padding-bottom: 8px;
    overflow-x: auto;
}

#write .md-fences.mock-cm {
    white-space: pre-wrap;
}

.md-fences.md-fences-with-lineno {
    padding-left: 0px;
}

#write.fences-no-line-wrapping .md-fences.mock-cm {
    white-space: pre;
    overflow-x: auto;
}

.md-fences.mock-cm.md-fences-with-lineno {
    padding-left: 8px;
}

.CodeMirror-line, twitterwidget {
    break-inside: avoid;
}

.footnotes {
    opacity: 0.8;
    font-size: 0.9rem;
    margin-top: 1em;
    margin-bottom: 1em;
}

.footnotes + .footnotes {
    margin-top: 0px;
}

.md-reset {
    margin: 0px;
    padding: 0px;
    border: 0px;
    outline: 0px;
    vertical-align: top;
    background: 0px 0px;
    text-decoration: none;
    text-shadow: none;
    float: none;
    position: static;
    width: auto;
    height: auto;
    white-space: nowrap;
    cursor: inherit;
    -webkit-tap-highlight-color: transparent;
    line-height: normal;
    font-weight: 400;
    text-align: left;
    box-sizing: content-box;
    direction: ltr;
}

li div {
    padding-top: 0px;
}

blockquote {
    margin: 1rem 0px;
}

li .mathjax-block, li p {
    margin: 0.5rem 0px;
}

li {
    margin: 0px;
    position: relative;
}

blockquote > :last-child {
    margin-bottom: 0px;
}

blockquote > :first-child, li > :first-child {
    margin-top: 0px;
}

.footnotes-area {
    color: rgb(136, 136, 136);
    margin-top: 0.714rem;
    padding-bottom: 0.143rem;
    white-space: normal;
}

#write .footnote-line {
    white-space: pre-wrap;
}

@media print {
    body, html {
        border: 1px solid transparent;
        height: 99%;
        break-after: avoid;
        break-before: avoid;
    }

    #write {
        margin-top: 0px;
        padding-top: 0px;
        border-color: transparent !important;
    }

    .typora-export * {
        -webkit-print-color-adjust: exact;
    }

    html.blink-to-pdf {
        font-size: 13px;
    }

    .typora-export #write {
        padding-left: 32px;
        padding-right: 32px;
        padding-bottom: 0px;
        break-after: avoid;
    }

    .typora-export #write::after {
        height: 0px;
    }
}

.footnote-line {
    margin-top: 0.714em;
    font-size: 0.7em;
}

a img, img a {
    cursor: pointer;
}

pre.md-meta-block {
    font-size: 0.8rem;
    min-height: 0.8rem;
    white-space: pre-wrap;
    background: rgb(204, 204, 204);
    display: block;
    overflow-x: hidden;
}

p > .md-image:only-child:not(.md-img-error) img, p > img:only-child {
    display: block;
    margin: auto;
}

p > .md-image:only-child {
    display: inline-block;
    width: 100%;
}

#write .MathJax_Display {
    margin: 0.8em 0px 0px;
}

.md-math-block {
    width: 100%;
}

.md-math-block:not(:empty)::after {
    display: none;
}

[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus {
    outline: 0px;
    box-shadow: none;
}

.md-task-list-item {
    position: relative;
    list-style-type: none;
}

.task-list-item.md-task-list-item {
    padding-left: 0px;
}

.md-task-list-item > input {
    position: absolute;
    top: 0px;
    left: 0px;
    margin-left: -1.2em;
    margin-top: calc(1em - 10px);
    border: none;
}

.math {
    font-size: 1rem;
}

.md-toc {
    min-height: 3.58rem;
    position: relative;
    font-size: 0.9rem;
    border-radius: 10px;
}

.md-toc-content {
    position: relative;
    margin-left: 0px;
}

.md-toc-content::after, .md-toc::after {
    display: none;
}

.md-toc-item {
    display: block;
    color: rgb(65, 131, 196);
}

.md-toc-item a {
    text-decoration: none;
}

.md-toc-inner:hover {
    text-decoration: underline;
}

.md-toc-inner {
    display: inline-block;
    cursor: pointer;
}

.md-toc-h1 .md-toc-inner {
    margin-left: 0px;
    font-weight: 700;
}

.md-toc-h2 .md-toc-inner {
    margin-left: 2em;
}

.md-toc-h3 .md-toc-inner {
    margin-left: 4em;
}

.md-toc-h4 .md-toc-inner {
    margin-left: 6em;
}

.md-toc-h5 .md-toc-inner {
    margin-left: 8em;
}

.md-toc-h6 .md-toc-inner {
    margin-left: 10em;
}

@media screen and (max-width: 48em) {
    .md-toc-h3 .md-toc-inner {
        margin-left: 3.5em;
    }

    .md-toc-h4 .md-toc-inner {
        margin-left: 5em;
    }

    .md-toc-h5 .md-toc-inner {
        margin-left: 6.5em;
    }

    .md-toc-h6 .md-toc-inner {
        margin-left: 8em;
    }
}

a.md-toc-inner {
    font-size: inherit;
    font-style: inherit;
    font-weight: inherit;
    line-height: inherit;
}

.footnote-line a:not(.reversefootnote) {
    color: inherit;
}

.md-attr {
    display: none;
}

.md-fn-count::after {
    content: ".";
}

code, pre, samp, tt {
    font-family: var(--monospace);
}

kbd {
    margin: 0px 0.1em;
    padding: 0.1em 0.6em;
    font-size: 0.8em;
    color: rgb(36, 39, 41);
    background: rgb(255, 255, 255);
    border: 1px solid rgb(173, 179, 185);
    border-radius: 3px;
    box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset;
    white-space: nowrap;
    vertical-align: middle;
}

.md-comment {
    color: rgb(162, 127, 3);
    opacity: 0.8;
    font-family: var(--monospace);
}

code {
    text-align: left;
    vertical-align: initial;
}

a.md-print-anchor {
    white-space: pre !important;
    border-width: initial !important;
    border-style: none !important;
    border-color: initial !important;
    display: inline-block !important;
    position: absolute !important;
    width: 1px !important;
    right: 0px !important;
    outline: 0px !important;
    background: 0px 0px !important;
    text-decoration: initial !important;
    text-shadow: initial !important;
}

.md-inline-math .MathJax_SVG .noError {
    display: none !important;
}

.html-for-mac .inline-math-svg .MathJax_SVG {
    vertical-align: 0.2px;
}

.md-math-block .MathJax_SVG_Display {
    text-align: center;
    margin: 0px;
    position: relative;
    text-indent: 0px;
    max-width: none;
    max-height: none;
    min-height: 0px;
    min-width: 100%;
    width: auto;
    overflow-y: hidden;
    display: block !important;
}

.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display {
    width: auto;
    margin: inherit;
    display: inline-block !important;
}

.MathJax_SVG .MJX-monospace {
    font-family: var(--monospace);
}

.MathJax_SVG .MJX-sans-serif {
    font-family: sans-serif;
}

.MathJax_SVG {
    display: inline;
    font-style: normal;
    font-weight: 400;
    line-height: normal;
    zoom: 90%;
    text-indent: 0px;
    text-align: left;
    text-transform: none;
    letter-spacing: normal;
    word-spacing: normal;
    overflow-wrap: normal;
    white-space: nowrap;
    float: none;
    direction: ltr;
    max-width: none;
    max-height: none;
    min-width: 0px;
    min-height: 0px;
    border: 0px;
    padding: 0px;
    margin: 0px;
}

.MathJax_SVG * {
    transition: none 0s ease 0s;
}

.MathJax_SVG_Display svg {
    vertical-align: middle !important;
    margin-bottom: 0px !important;
    margin-top: 0px !important;
}

.os-windows.monocolor-emoji .md-emoji {
    font-family: "Segoe UI Symbol", sans-serif;
}

.md-diagram-panel > svg {
    max-width: 100%;
}

[lang="flow"] svg, [lang="mermaid"] svg {
    max-width: 100%;
    height: auto;
}

[lang="mermaid"] .node text {
    font-size: 1rem;
}

table tr th {
    border-bottom: 0px;
}

video {
    max-width: 100%;
    display: block;
    margin: 0px auto;
}

iframe {
    max-width: 100%;
    width: 100%;
    border: none;
}

.highlight td, .highlight tr {
    border: 0px;
}

svg[id^="mermaidChart"] {
    line-height: 1em;
}

mark {
    background: rgb(255, 255, 0);
    color: rgb(0, 0, 0);
}

.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong {
    color: inherit;
}

mark .md-meta {
    color: rgb(0, 0, 0);
    opacity: 0.3 !important;
}


.CodeMirror {
    height: auto;
}

.CodeMirror.cm-s-inner {
    background: inherit;
}

.CodeMirror-scroll {
    overflow: auto hidden;
    z-index: 3;
}

.CodeMirror-gutter-filler, .CodeMirror-scrollbar-filler {
    background-color: rgb(255, 255, 255);
}

.CodeMirror-gutters {
    border-right: 1px solid rgb(221, 221, 221);
    background: inherit;
    white-space: nowrap;
}

.CodeMirror-linenumber {
    padding: 0px 3px 0px 5px;
    text-align: right;
    color: rgb(153, 153, 153);
}

.cm-s-inner .cm-keyword {
    color: rgb(119, 0, 136);
}

.cm-s-inner .cm-atom, .cm-s-inner.cm-atom {
    color: rgb(34, 17, 153);
}

.cm-s-inner .cm-number {
    color: rgb(17, 102, 68);
}

.cm-s-inner .cm-def {
    color: rgb(0, 0, 255);
}

.cm-s-inner .cm-variable {
    color: rgb(0, 0, 0);
}

.cm-s-inner .cm-variable-2 {
    color: rgb(0, 85, 170);
}

.cm-s-inner .cm-variable-3 {
    color: rgb(0, 136, 85);
}

.cm-s-inner .cm-string {
    color: rgb(170, 17, 17);
}

.cm-s-inner .cm-property {
    color: rgb(0, 0, 0);
}

.cm-s-inner .cm-operator {
    color: rgb(152, 26, 26);
}

.cm-s-inner .cm-comment, .cm-s-inner.cm-comment {
    color: rgb(170, 85, 0);
}

.cm-s-inner .cm-string-2 {
    color: rgb(255, 85, 0);
}

.cm-s-inner .cm-meta {
    color: rgb(85, 85, 85);
}

.cm-s-inner .cm-qualifier {
    color: rgb(85, 85, 85);
}

.cm-s-inner .cm-builtin {
    color: rgb(51, 0, 170);
}

.cm-s-inner .cm-bracket {
    color: rgb(153, 153, 119);
}

.cm-s-inner .cm-tag {
    color: rgb(17, 119, 0);
}

.cm-s-inner .cm-attribute {
    color: rgb(0, 0, 204);
}

.cm-s-inner .cm-header, .cm-s-inner.cm-header {
    color: rgb(0, 0, 255);
}

.cm-s-inner .cm-quote, .cm-s-inner.cm-quote {
    color: rgb(0, 153, 0);
}

.cm-s-inner .cm-hr, .cm-s-inner.cm-hr {
    color: rgb(153, 153, 153);
}

.cm-s-inner .cm-link, .cm-s-inner.cm-link {
    color: rgb(0, 0, 204);
}

.cm-negative {
    color: rgb(221, 68, 68);
}

.cm-positive {
    color: rgb(34, 153, 34);
}

.cm-header, .cm-strong {
    font-weight: 700;
}

.cm-del {
    text-decoration: line-through;
}

.cm-em {
    font-style: italic;
}

.cm-link {
    text-decoration: underline;
}

.cm-error {
    color: red;
}

.cm-invalidchar {
    color: red;
}

.cm-constant {
    color: rgb(38, 139, 210);
}

.cm-defined {
    color: rgb(181, 137, 0);
}

div.CodeMirror span.CodeMirror-matchingbracket {
    color: rgb(0, 255, 0);
}

div.CodeMirror span.CodeMirror-nonmatchingbracket {
    color: rgb(255, 34, 34);
}

.cm-s-inner .CodeMirror-activeline-background {
    background: inherit;
}

.CodeMirror {
    position: relative;
    overflow: hidden;
}

.CodeMirror-scroll {
    height: 100%;
    outline: 0px;
    position: relative;
    box-sizing: content-box;
    background: inherit;
}

.CodeMirror-sizer {
    position: relative;
}

.CodeMirror-gutter-filler, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-vscrollbar {
    position: absolute;
    z-index: 6;
    display: none;
}

.CodeMirror-vscrollbar {
    right: 0px;
    top: 0px;
    overflow: hidden;
}

.CodeMirror-hscrollbar {
    bottom: 0px;
    left: 0px;
    overflow: hidden;
}

.CodeMirror-scrollbar-filler {
    right: 0px;
    bottom: 0px;
}

.CodeMirror-gutter-filler {
    left: 0px;
    bottom: 0px;
}

.CodeMirror-gutters {
    position: absolute;
    left: 0px;
    top: 0px;
    padding-bottom: 30px;
    z-index: 3;
}

.CodeMirror-gutter {
    white-space: normal;
    height: 100%;
    box-sizing: content-box;
    padding-bottom: 30px;
    margin-bottom: -32px;
    display: inline-block;
}

.CodeMirror-gutter-wrapper {
    position: absolute;
    z-index: 4;
    background: 0px 0px !important;
    border: none !important;
}

.CodeMirror-gutter-background {
    position: absolute;
    top: 0px;
    bottom: 0px;
    z-index: 4;
}

.CodeMirror-gutter-elt {
    position: absolute;
    cursor: default;
    z-index: 4;
}

.CodeMirror-lines {
    cursor: text;
}

.CodeMirror pre {
    border-radius: 0px;
    border-width: 0px;
    background: 0px 0px;
    font-family: inherit;
    font-size: inherit;
    margin: 0px;
    white-space: pre;
    overflow-wrap: normal;
    color: inherit;
    z-index: 2;
    position: relative;
    overflow: visible;
}

.CodeMirror-wrap pre {
    overflow-wrap: break-word;
    white-space: pre-wrap;
    word-break: normal;
}

.CodeMirror-code pre {
    border-right: 30px solid transparent;
    width: fit-content;
}

.CodeMirror-wrap .CodeMirror-code pre {
    border-right: none;
    width: auto;
}

.CodeMirror-linebackground {
    position: absolute;
    left: 0px;
    right: 0px;
    top: 0px;
    bottom: 0px;
    z-index: 0;
}

.CodeMirror-linewidget {
    position: relative;
    z-index: 2;
    overflow: auto;
}

.CodeMirror-wrap .CodeMirror-scroll {
    overflow-x: hidden;
}

.CodeMirror-measure {
    position: absolute;
    width: 100%;
    height: 0px;
    overflow: hidden;
    visibility: hidden;
}

.CodeMirror-measure pre {
    position: static;
}

.CodeMirror div.CodeMirror-cursor {
    position: absolute;
    visibility: hidden;
    border-right: none;
    width: 0px;
}

.CodeMirror div.CodeMirror-cursor {
    visibility: hidden;
}

.CodeMirror-focused div.CodeMirror-cursor {
    visibility: inherit;
}

.cm-searching {
    background: rgba(255, 255, 0, 0.4);
}

@media print {
    .CodeMirror div.CodeMirror-cursor {
        visibility: hidden;
    }
}


:root {
    --side-bar-bg-color: white;
    --window-border: none;
    --search-select-bg-color: #575c61;
    --active-file-bg-color: #f1f4f5;
    --item-hover-bg-color: #f1f4f5;
    --item-hover-text-color: black;
    --control-text-color: #555;
}

@include-when-export url(https://raw.githubusercontent.com/slashfoo/lmweb/master/style/latinmodern-mono-light.css);

html {
    font-size: 12pt;
}

#write {
    font-family: "STIX2Text", "Times New Roman", "serif";
    line-height: 1.5em;
    padding: 10%;
    padding-top: 5%;
}

.file-list-item-summary {
    height: 36px;
}

.file-list-item {
    padding-top: 18px !important;
    padding-bottom: 18px;
}

#sidebar-loading-template.file-list-item {
    padding-top: 0 !important;
}

a, a:visited {
    color: #a00;
}

h1, h2, h3, h4, h5, h6 {
    font-family: inherit;
    line-height: 1.5em;
    margin-bottom: 1em;
    margin-top: 1em;
}

h1 {
    font-size: 2.4em;
}

#write h1 {
    text-align: center;
}

h2 {
    font-size: 1.8em;
}

h3 {
    font-size: 1.4em;
}

h4 {
    font-size: 1.2em;
}

h5 {
    font-size: 1.1em;
}

h6 {
    font-size: 1em;
}

p {
    margin-top: 1em;
    margin-bottom: 1em;
    text-align: justify;
}

pre, code {
    font-family: 'Latin Modern Mono Light', "Latin Modern Mono", monospace !important;
    background-color: #ebebeb;
}

.footnotes {
    display: list-item;
    margin-left: 1em;
}

.md-fences {
    border: 1px solid;
}

.md-fences.md-fences-with-lineno {
    border: none;
}

.CodeMirror-linenumber {
    color: #333;
}

*.in-text-selection,
::selection,
.CodeMirror-selected {
    background: var(--search-select-bg-color);
    color: var(--search-select-text-color) !important;
    text-shadow: none;
}

a.md-toc-inner {
    color: var(--text-color);
}

.cm-s-typora-default .cm-link {
    color: #a00;
    text-decoration: underline;
}

.cm-s-typora-default .cm-header, .cm-s-typora-default .cm-property {
    color: black;
}

#typora-source .CodeMirror-lines {
    -webkit-font-smoothing: auto;
    max-width: 1000px;
}

.md-def-name:before,
.md-def-name:after {
    color: #2d2d2d;
}

sup.md-footnote {
    background-color: initial;
    color: inherit;
}

mark {
    background: #fff387;
}

td, th {
    border: 1px solid;
    padding-left: 1ch;
    padding-right: 1ch;
}

/*table tr[cid]:first-child > td {
    border-top: 3px double;
}*/

th {
    border-bottom: 0;
    padding-top: 2px;
    background: #575c61;
    border-color: #333;
    color: #f3f3f3;
}

pre.md-meta-block {
    border: 1px solid #a2a9b1;
    background-color: #f8f9fa;
    padding: 5px;
    margin-bottom: 1em;
}

.task-list-item input:before {
    content: '\221A';
    display: inline-block;
    width: 1.25rem;
    height: 1.6rem;
    vertical-align: middle;
    text-align: center;
    color: #bbb;
    background-color: inherit;
}

.task-list-item input:checked:before,
.task-list-item input[checked]:before {
    color: inherit;
}

.md-task-list-item > input {
    top: auto;
    margin-left: -1.1em;
    font-size: 1.3em;
    margin-top: 0px;
    -webkit-appearance: none;
}

.md-task-list-item input:before {
    content: '\2610';
    display: inline-block;
    width: 1.25rem;
    height: 1.6rem;
    vertical-align: middle;
    text-align: center;
    color: #bbb;
    background-color: inherit;
}

.md-task-list-item input:checked:before,
.md-task-list-item input[checked]:before {
    color: inherit;
    content: '\2611';
}

.task-list-item {
    padding-left: 1.5em;
}

blockquote {
    font-style: italic;
    padding: 0.25em 24px;
    position: relative;
    color: #383838;
    border-left: 2px solid;
}

#write > blockquote {
    padding: 0.25em 30px;
    margin-left: -32px;
    width: calc(100% + 32px);
}

#write > .md-fences-with-lineno {
    margin-left: -33px;
    color: black;
}

.CodeMirror-linenumber {
    min-width: 25px;
}

.md-header {
    font-size: inherit !important;
}

/*blockquote:before {
    display: block;
    content: "\201C";
    font-size: 80px;
    position: absolute;
    left: -20px;
    top: -20px;
    color: #7a7a7a;
}*/




    </style>
</head>
<body>
<h1 id="neural-networks">Neural Networks</h1>
<p>In the perceptron algorithm we have two parameters <span class="math">\(w\in \mathbb{R}^n\)</span> and <span class="math">\(b \in \mathbb{R}\)</span> and then the classification <span class="math">\(\hat y\)</span> to two classes for a vector <span class="math">\(x\in \mathbb{R}^n\)</span> is performed as</p>
<div class="math">
\[
\hat y = \text{sign}(w \times x + b )
\]</div>
<p>Another way we can define the perceptron algorithm is:</p>
<img src="Resources/09 - Neural Networks/81708680-2230-4dd6-ab3c-eecb66eb8790.png" alt="81708680-2230-4dd6-ab3c-eecb66eb8790" style="scale:0.33;" />
<p>From here we can combine different perceptron classifiers to make a complex classifier by letting them use the same input and have their own outputs into other perceptron:</p>
<img src="Resources/09 - Neural Networks/810cb375-c229-4415-9d13-c3f6e890bf4b.png" alt="810cb375-c229-4415-9d13-c3f6e890bf4b" style="scale:0.33;" />
<p>Another string motivation for  forming such combinations of simple classifiers is the <strong>Universal Approximation Theorem</strong>. This theorem states that if <span class="math">\(\sigma:\mathbb{R} \rightarrow \mathbb{R}\)</span> is a non-constant, bounded and continuous function, and if <span class="math">\(f\)</span> is a continuous function on unity hypercube <span class="math">\([0,1]^n\)</span>, then for any $\epsilon &gt; 0 $ there exists <span class="math">\(N \in \mathbb{N}, v_i,b_i \in \mathbb{R}, w_i \in \mathbb{R}^n\)</span> such that:</p>
<div class="math">
\[
F(x) = \sum_{i=1}^nv_i \sigma(w_i \times x + b_i)\\
|F(x) - f(x)| &lt; \epsilon,~~ \forall x \in [0,1]^m
\]</div>
<p>We can see that the approximation is exactly captured by the following network:</p>
<img src="Resources/09 - Neural Networks/a138c0fc-7b95-478e-b327-995b777b6046.png" alt="a138c0fc-7b95-478e-b327-995b777b6046" style="scale:0.33;" />
<h2 id="representation">Representation</h2>
<p>Neural networks can be represented in layers. Here we have an example:</p>
<img src="Resources/09 - Neural Networks/e876d5d3-a25a-42b7-9419-17268420d059.png" alt="e876d5d3-a25a-42b7-9419-17268420d059" style="scale:0.33;" />
<p>But this can be rewritten more concisely as:</p>
<img src="Resources/09 - Neural Networks/0031e411-0538-44f8-a7dc-c87ff9afa98c.png" alt="0031e411-0538-44f8-a7dc-c87ff9afa98c" style="scale:0.33;" />
<p>We can keep adding more hidden layers and the network can be described as:</p>
<img src="Resources/09 - Neural Networks/77eba302-baa0-4547-8961-a477df8779a3.png" alt="77eba302-baa0-4547-8961-a477df8779a3" style="scale:0.33;" />
<h3 id="hidden-layers">Hidden Layers</h3>
<p>Each hidden layer is composed of an affine function, followed by non-linearity. There are several different functions we can use for this part:</p>
<ul>
<li><span class="math">\(\sigma(z) = \text{sign}(z)\)</span>: Used for the original perceptron, but it is not usable in neural nets because it is not differentiable at 0, and everywhere else the gradient it 0, so we can't optimize the parameters.</li>
<li><span class="math">\(\sigma(z) = \tanh(z)\)</span></li>
<li><span class="math">\(\sigma(z) = \max(0,z)\)</span></li>
<li><span class="math">\(\sigma(z) = \max(0,z) + \min(9,sz)\)</span>  <span class="math">\((0 &lt;s&lt;1)\)</span></li>
<li><span class="math">\(\sigma(z) = \frac 1 {1+ e^{-z}}\)</span></li>
</ul>
<h3 id="output-layers">Output Layers</h3>
<p>In a <strong><span class="math">\(K\)</span>-class classification</strong> we normally label the classes from <span class="math">\(1,\dots, k\)</span> but that doesn't mean that elements from class <span class="math">\(3\)</span> are more similar to those in class <span class="math">\(4\)</span> than any other class. This is way it makes no sense to have directly a one dimensionally output <span class="math">\(\hat y\)</span> trying to estimate the correct label. To solve this, the output layer will produce a <span class="math">\(K\)</span>-dimensional vector and then a SoftMax function will convert it to class probabilities:</p>
<img src="Resources/09 - Neural Networks/31892957-a036-4371-a83a-ee19bb05f0e2.png" alt="31892957-a036-4371-a83a-ee19bb05f0e2" style="scale:0.33;" />
<p>With:</p>
<div class="math">
\[
[\text{softmax}(z)]_k = \frac {e^{z_k}}{\sum_{l=1}^K e^{z_l}}
\]</div>
<p>For representing the class <span class="math">\(y\)</span> of a training data point $(x,y)$we use <strong>one-hot</strong> representation that creates a <span class="math">\(K\)</span>-dimensional vector and all the probabilities are zero except for the <span class="math">\(y^{th}\)</span> place:</p>
<div class="math">
\[
\text{onehot}(y) = [\delta_{1y},\dots,\delta_{Ky}]^T = [0,\dots,1,\dots,0]^T \in \mathbb{R}^K
\]</div>
<p>The <strong>loss function</strong> of the output layer measures how far the prediction <span class="math">\(\hat y \in [0,1]^K\)</span> is from the target vector generated by the one-hot function. The loss function can be one of these functions:</p>
<ul>
<li><p><strong>Squared Difference</strong>: This function will have 0 loss if the prediction matches the target but <span class="math">\(&gt;0\)</span> otherwise. The function is:</p>
<div class="math">
\[
J(\hat y,y) = ||\hat y - y||^2
\]</div>
</li>
<li><p><strong>Negative lob-likelihood</strong>:</p>
<div class="math">
\[
J(\hat y, y) = -y^T \log(\hat y) = - \sum_{i=1}^K y_i \log(\hat y_i) = -\log \hat y_l
\]</div>
<p>Where <span class="math">\(l\)</span> is the index of the target class of the training data point <span class="math">\((x,l)\)</span>.</p>
</li>
</ul>
<h2 id="training">Training</h2>
<p>Let the training data be <span class="math">\(\mathcal T = \{(x_1,y_1) ,\dots,(x_N,y_N)\}\)</span> where we can assume that the labels  <span class="math">\(y_i\)</span>'s have been  converted to their one-hot representation. Let <span class="math">\(\theta\)</span> represent all the parameters of the neural net, we want to minimize:</p>
<div class="math">
\[
J(\mathcal T;\theta)=\sum_{(x,y) \in \mathcal T}J(\hat y(x),y)
\]</div>
<p>To do this we are using gradient-based methods and minimizing with respect to <span class="math">\(\theta\)</span>. We need to evaluate the gradient of loss with respect to the neural net parameters and the derivative of the loss function to use it for updates of the gradient-descent type:</p>
<div class="math">
\[
\theta_{t+1} \leftarrow (\theta_t - \mu) \sum_{(x,t) \in \mathcal{T' \subseteq T}} \frac{\partial J(\hat y(x),y)}{\partial \theta} 
\]</div>
<p>where <span class="math">\(\mu\)</span> is the learning rate and we do not need to do this over the entire dataset.</p>
<h3 id="computing-the-gradient">Computing the Gradient</h3>
<p>When computing the gradient, we will make use of the chain rule. Let <span class="math">\(f:\mathbb{R}^n\rightarrow R\)</span> and <span class="math">\(g:\mathbb{R}^m\rightarrow\mathbb{R}^n\)</span> such that <span class="math">\(f(g(x)) = f(y)\)</span>, it holds that:</p>
<div class="math">
\[
\frac{\partial f(g(\bold x)) }{\partial x_k} = \sum_{i=1}^n \frac{\partial f}{\partial y_i} \frac{\partial y_i}{\partial x_k}
\]</div>
<p>We can rewrite this in matrix form as:</p>
<div class="math">
\[
\frac{\partial f(g(\bold x)) }{\partial \bold x} = \frac {\partial f}{\partial \bold y} \frac {\partial \bold y}{\partial \bold x} = f' \bold y'
\]</div>
<p>where <span class="math">\(f' = \partial f / \partial \bold y\)</span> and <span class="math">\(\bold y' = \partial \bold y / \partial \bold x\)</span>  are the Jacobian matrices:</p>
<div class="math">
\[
f' = \left[\frac{\partial f}{\partial y_1},\dots,\frac{\partial f}{\partial y_n}\right] \\
\bold y' = 
\left[
\array{
\frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_1}{\partial x_2}&amp;\dots &amp;\frac{\partial y_1}{\partial x_m}\\
\frac{\partial y_2}{\partial x_1} &amp;\frac{\partial y_2}{\partial x_2} &amp;\dots&amp;\vdots\\
\vdots&amp; \dots&amp;\ddots&amp;\vdots\\
\frac{\partial y_n}{\partial x_1} &amp; \dots&amp; \dots &amp; \frac{\partial y_n}{\partial x_m}
}
\right]
\]</div>
<h4 id="example">Example</h4>
<p>We can calculate the gradient of the following neural net using back propagation:</p>
<img src="Resources/09 - Neural Networks/050ec9b6-bbd7-42bc-a85b-c54fb1576521.png" alt="050ec9b6-bbd7-42bc-a85b-c54fb1576521" style="scale:0.33;" />
<p>The set of parameters <span class="math">\(\theta= \{W_1,W_2,W_3,b_1,b_2,b_3\}\)</span>. For the loss function we will sue squared difference.</p>
<ol>
<li><p>First we need to compute <span class="math">\(v_3 =\left. \frac {\partial J}{\partial \hat y}\right| _{\hat y}\)</span>, this is a row vector <span class="math">\(\bold v_3 = 2(\hat y -y)^T\in \mathbb{R}^K\)</span></p>
</li>
<li><p>Then we need to calculate the derivatives of <span class="math">\(J\)</span> with respect to <span class="math">\(W_3\)</span> and <span class="math">\(b_3\)</span>:</p>
<div class="math">
\[
\frac{\partial J}{\partial b_3} = \bold v_3 \left.\frac{\partial J}{\partial b_3}\right|_{\bold a_3} = \bold v_3\\
\frac{\partial J}{\partial (W_3)_{kl}} = \bold v_3 \frac{\partial \hat y}{\partial (W_3)_{kl}}  = \bold v_3 [0,\dots,(\bold a_3)_l,\dots,0]^T = (\bold v_3)_k (\bold a_3)_l
\]</div>
<p>Where in <span class="math">\([0,\dots,(a_3)_l,\dots,0]^T\)</span> <span class="math">\((a_3)_l\)</span> is at the <span class="math">\(k^{th}\)</span> position.</p>
<p>Doing that process for all elements of the matrix <span class="math">\(W_3\)</span>,we can obtain the following matrix:</p>
<div class="math">
\[
\frac{\partial J}{\partial W_3} = 
\left [\array{
\frac{\partial J}{\partial (W_3)_{11}} &amp; \dots &amp; \frac{\partial J}{\partial (W_3)_{1m_1}}\\
\vdots&amp; \ddots &amp; \vdots
\\
\frac{\partial J}{\partial (W_3)_{K1}}&amp; \dots &amp; \frac{\partial J}{\partial (W_3)_{Km_1}}
}\right] = \bold v_3 ^T \bold a_3^T
\]</div>
</li>
<li><p>Now we are going to compute <span class="math">\(\bold v_2\)</span>:</p>
<div class="math">
\[
\bold v_2 = \bold v_3 \left.\frac{\partial \hat y}{\partial \bold a_3} \right|_{\bold a_3}
 \left.\frac{\partial \bold a_3}{\partial \bold z_3} \right|_{\bold z_3}
 =
 \bold (v_3 W_3) \odot \sigma'(\bold z_2)
\]</div>
<p>Where <span class="math">\(\sigma'(\bold x) = [\sigma'(x_1),\dots,\sigma'(x_n)]\)</span> and <span class="math">\(\sigma'\)</span> is the derivative of <span class="math">\(\sigma\)</span>. The symbol <span class="math">\(\odot\)</span> represent the element-wise product of the matrices.</p>
</li>
<li><p>We can now compute <span class="math">\(W_2,b_2\)</span> as:</p>
<div class="math">
\[
\frac{\partial J}{\partial b_2} =\bold v_2\\
\frac{\partial J}{\partial W_2} = \bold v_2^T\bold a_2^T
\]</div>
</li>
<li><p>For <span class="math">\(\bold v_1\)</span> we are repeating step 3:</p>
<div class="math">
\[
\bold v_1 = (\bold v_2 W_2) \odot \sigma'(\bold z_2)
\]</div>
</li>
<li><p>And lastly we can get the parameters <span class="math">\(W_1,b_2\)</span> as:</p>
<div class="math">
\[
\frac{\partial J}{\partial b_1} =\bold v_1\\
\frac{\partial J}{\partial W_1} = \bold v_1^T\bold a_1^T
\]</div>
</li>
</ol>
<h2 id="deep-learning">Deep Learning</h2>
<p>Deep learning is a very successful branch of machine learning that has made a lot of progress in recent years. This field includes Convolutional Neural Nets (CNNs), where the inputs are translation-invariant and warpable, like in images. It also includes Recurrent Neural Networks (RNNs) which allow previous outputs to be  used as inputs and are very common in speech recognition. From now on we will only discus <strong>CNNs</strong></p>
<p>The main advantage of CNNs is that they reduce the number of parameters needed. For example if we have a <span class="math">\(64\times 64\)</span> pixels image and we try to implement a NN with fully connected layers we end up with <span class="math">\((64^2)^2\)</span> connections. If we use CNNs with a <span class="math">\(5\times 5\)</span> neighborhood for each neuron in the second layer and we make the parameters for all <span class="math">\(5\times 5\)</span> connections shared, we only need <span class="math">\(25\)</span> connections.</p>
<p>The typical structure for a CNN involves many convolutions, subsampling and finally some full connection layers to generate the labels:</p>
<img src="Resources/09 - Neural Networks/565d9441-4f66-4d2e-a750-242a0fb23eb7.png" alt="565d9441-4f66-4d2e-a750-242a0fb23eb7" style="scale:0.33;" />
<h3 id="pooling">Pooling</h3>
<p>Pooling is a method to subsample our data and keep the important features. The idea is that we have to select a filter and then the stride. The filter will represent the area we want to output of and the stride will gives us the area of the input. A very used function for pooling is max pooling, which takes the higher number from each section of the input and returns in tin the output:</p>
<img src="Resources/09 - Neural Networks/a10a0285-0863-41b7-b2ef-662f076fb8dd.png" alt="a10a0285-0863-41b7-b2ef-662f076fb8dd" style="scale:0.33;" />
<h3 id="dropout">Dropout</h3>
<p>Drop out increases significantly overfitting by removing neurons that are not useful for the classification.</p>

</body>
</html>